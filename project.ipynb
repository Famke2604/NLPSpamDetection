{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"10\"> Spam Detection in emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"3\"> Authors: M. Hooghiemstra and F. Nouwens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Reading in the data </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import random\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------TRAINING DATA----------------------------\n",
    "#Reading in the spam and ham files\n",
    "def readTrain():\n",
    "    pathSpam = './trainAnnotated/spam/'\n",
    "\n",
    "    spamFiles = []\n",
    "    # r=root, d=directories, f = files\n",
    "    for r, d, f in os.walk(pathSpam):\n",
    "        for file in f:\n",
    "            if '.txt' in file:\n",
    "                spamFiles.append(os.path.join(r, file))\n",
    "\n",
    "    spam = [0 for j in range(0,len(spamFiles))]\n",
    "    for index,f in enumerate(spamFiles):\n",
    "        #print(f)\n",
    "        spam[index] = open(f, encoding='latin-1').read().splitlines()\n",
    "\n",
    "#     probeerselSpam = [0 for j in range(0,len(spamFiles))]\n",
    "#     for index,f in enumerate(spamFiles):\n",
    "#     #print(f)\n",
    "#         probeerselSpam[index] = open(f, encoding='latin-1').read()\n",
    "        \n",
    "# #     print('probeerselSpam',probeerselSpam)\n",
    "#     #print(spam)\n",
    "    pathHam = './trainAnnotated/ham/'\n",
    "\n",
    "    hamFiles = []\n",
    "    # r=root, d=directories, f = files\n",
    "    for r, d, f in os.walk(pathHam):\n",
    "        for file in f:\n",
    "            if '.txt' in file:\n",
    "                hamFiles.append(os.path.join(r, file))\n",
    "\n",
    "    ham = [0 for j in range(0,len(hamFiles))]\n",
    "    for index,f in enumerate(hamFiles):\n",
    "        ham[index] = open(f,encoding='latin-1').read().splitlines()\n",
    "        \n",
    "#     probeerselHam = [0 for j in range(0,len(hamFiles))]\n",
    "#     for index,f in enumerate(hamFiles):\n",
    "#     #print(f)\n",
    "#         probeerselHam[index] = open(f, encoding='latin-1').read()\n",
    "    \n",
    "    spamList, hamList = optimalDataFormat(spam, ham)\n",
    "    \n",
    "    return (spamList, hamList )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------TEST DATA----------------------------------\n",
    "#Reading in the spam and ham files\n",
    "def readTest():\n",
    "    pathSpam = './testAnnotated/spam/'\n",
    "\n",
    "    spamFiles = []\n",
    "    # r=root, d=directories, f = files\n",
    "    for r, d, f in os.walk(pathSpam):\n",
    "        for file in f:\n",
    "            if '.txt' in file:\n",
    "                spamFiles.append(os.path.join(r, file))\n",
    "\n",
    "    spam = [0 for j in range(0,len(spamFiles))]\n",
    "    for index,f in enumerate(spamFiles):\n",
    "        #print(f)\n",
    "        spam[index] = open(f, encoding='latin-1').read().splitlines()\n",
    "\n",
    "    #print(spam)\n",
    "    pathHam = './testAnnotated/ham/'\n",
    "\n",
    "    hamFiles = []\n",
    "    # r=root, d=directories, f = files\n",
    "    for r, d, f in os.walk(pathHam):\n",
    "        for file in f:\n",
    "            if '.txt' in file:\n",
    "                hamFiles.append(os.path.join(r, file))\n",
    "\n",
    "    ham = [0 for j in range(0,len(hamFiles))]\n",
    "    for index,f in enumerate(hamFiles):\n",
    "        ham[index] = open(f,encoding='latin-1').read().splitlines()\n",
    "    \n",
    "    spamList, hamList = optimalDataFormat(spam, ham)\n",
    "    \n",
    "    return (spamList, hamList)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Pre-processing the data </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDict(text):\n",
    "    dictionary = dict([(word,True) for word in text]) \n",
    "    return dictionary\n",
    "\n",
    "def removeStopWords(text):\n",
    "    from nltk.corpus import stopwords\n",
    "    stop_words = stopwords.words('english') \n",
    "    #print(stop_words)\n",
    "    text = [word for word in text if word not in stop_words]\n",
    "    return text\n",
    "\n",
    "def removePunc(text):\n",
    "    punc = r\"\\\\|\\/|\\%|\\$|\\-|\\^|\\[|\\]|\\<|\\>|\\&|\\(|\\)\"        \n",
    "    text = [word for word in text if not(re.match(punc,word))]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimalDataFormat(spam, ham):\n",
    "    spamList= []\n",
    "    hamList = []\n",
    "\n",
    "    for i,file in enumerate(spam):\n",
    "        tempSent = []\n",
    "        for j,sentence in enumerate(file):\n",
    "            sents = []\n",
    "            #print(spam[i][j])\n",
    "            sentences = sent_tokenize(spam[i][j])\n",
    "    #         print('the sentences:',sentences)\n",
    "            for sent in sentences:\n",
    "    #             print('sentence:',sent)\n",
    "                words = word_tokenize(sent)\n",
    "    #             print('words tokenized:',words)\n",
    "                words = removeStopWords(words)\n",
    "                words = removePunc(words)\n",
    "                sents += words\n",
    "    #             print('preprocessed words:',sents)\n",
    "    #             print(\"end of for loop sent in sentences\")\n",
    "            tempSent += sents\n",
    "    #         print('sentences in file',tempSent)\n",
    "        spamList.append(tempSent)\n",
    "    #     print('spamlist:',spamList)\n",
    "\n",
    "    for i,file in enumerate(ham):\n",
    "        tempSent = []\n",
    "        for j,sentence in enumerate(file):\n",
    "            sents = []\n",
    "            #print(ham[i][j])\n",
    "            sentences = sent_tokenize(ham[i][j])\n",
    "    #         print('the sentences:',sentences)\n",
    "            for sent in sentences:\n",
    "    #             print('sentence:',sent)\n",
    "                words = word_tokenize(sent)\n",
    "    #             print('words tokenized:',words)\n",
    "                words = removeStopWords(words)\n",
    "                words = removePunc(words)\n",
    "                sents += words\n",
    "    #             print('preprocessed words:',sents)\n",
    "    #             print(\"end of for loop sent in sentences\")\n",
    "            tempSent += sents\n",
    "    #         print('sentences in file',tempSent)\n",
    "        hamList.append(tempSent)\n",
    "    #     print('hamlist:',hamList)\n",
    "    return (spamList, hamList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTotalSet(spamList, hamList):\n",
    "    hamList2 = []\n",
    "    spamList2 = []\n",
    "    for mail in hamList:\n",
    "        hamList2.append((createDict(mail),\"ham\"))\n",
    "\n",
    "    for mail in spamList:\n",
    "        spamList2.append((createDict(mail),\"spam\"))\n",
    "\n",
    "\n",
    "    #We combine the two dataset lists to eventually train the classifiers\n",
    "    totalTrain = hamList2 + spamList2\n",
    "\n",
    "    #To get unbiased results, we shuffle the dataset\n",
    "    random.shuffle(totalTrain)\n",
    "    return totalTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTotalSetNoDict(spamList, hamList):\n",
    "    hamList2 = []\n",
    "    spamList2 = []\n",
    "    for i,message in enumerate(hamList):\n",
    "        hamList2.append((hamList[i],\"ham\"))\n",
    "\n",
    "    for i,message in enumerate(spamList):\n",
    "        hamList2.append((spamList[i],\"spam\"))\n",
    "        \n",
    "\n",
    "    #print('hamList', hamList2[1])\n",
    "    #We combine the two dataset lists to eventually train the classifiers\n",
    "    totalTrain = hamList2 + spamList2\n",
    "\n",
    "    #To get unbiased results, we shuffle the dataset\n",
    "    random.shuffle(totalTrain)\n",
    "    return totalTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running the whole code to obtain the total train data:\n",
    "spamList, hamList = readTrain()\n",
    "totalTrain = createTotalSet(spamList,hamList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "spamList, hamList = readTest()\n",
    "totalTest = createTotalSet(spamList, hamList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create train set\n",
      "create test set\n"
     ]
    }
   ],
   "source": [
    "print('create train set')\n",
    "spamList, hamList = readTrain()\n",
    "totalTrainNoDict = createTotalSetNoDict(spamList,hamList)\n",
    "print('create test set')\n",
    "spamList, hamList = readTest()\n",
    "totalTestNoDict = createTotalSetNoDict(spamList, hamList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Na√Øve Bayes Classifier </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is  97.46666666666667 %\n",
      "              Precision          Recall            F-score\n",
      "Macro (0.9756441682818379, 0.9746666666666666, 0.9746536442723461, None)\n",
      "Micro (0.9746666666666667, 0.9746666666666667, 0.9746666666666667, None)\n",
      "TP:  357\n",
      "FP:  18\n",
      "TN:  374\n",
      "FN:  1\n"
     ]
    }
   ],
   "source": [
    "#NAIVE BAYES CLASSIFIER\n",
    "def NaiveBayes(trainX,testX):\n",
    "    from sklearn.naive_bayes import MultinomialNB  \n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from nltk.classify import NaiveBayesClassifier\n",
    "    \n",
    "    labelsTest = []\n",
    "    testSet = []\n",
    "    for item in testX:\n",
    "       # print(item[1])\n",
    "        testSet.append(item[0])\n",
    "        labelsTest.append(item[1]) \n",
    "        \n",
    "    labelsTrain = []\n",
    "    trainSet = []\n",
    "    for item in trainX:\n",
    "       # print(item[1])\n",
    "        trainSet.append((item[0],item[1]))\n",
    "        labelsTrain.append(item[1]) \n",
    "    \n",
    "#     print(trainSet[0])\n",
    "\n",
    "    NBmodel1 = MultinomialNB()\n",
    "#     for i, message in enumerate(trainSet):\n",
    "#         NBmodel1.fit(trainSet[i],labelsTrain)\n",
    "    \n",
    "    #NBmodel1.fit(trainSet,labelsTrain)\n",
    "#     print('trainX',trainX[1])\n",
    "    NBmodel2 = NaiveBayesClassifier.train(trainX)\n",
    "    \n",
    "\n",
    "    classifications = []\n",
    "    for i,message in enumerate(testSet):\n",
    "#         print('message is:', message)\n",
    "#         classification = NBmodel1.predict(message)\n",
    "        classification = NBmodel2.classify(message)\n",
    "#         print('Message ', i, 'is:', classification)\n",
    "        classifications.append(classification)\n",
    "#         print('classification',classifications[i])\n",
    "#         print('Actual value:', testX[i][1])\n",
    "\n",
    "        \n",
    "#     accuracy = nltk.classify.util.accuracy(NBmodel2, testSet)\n",
    "#     print('accuracy:', accuracy*100,'%')\n",
    "#     prediction = NBmodel1.predict(testSet)\n",
    "    accuracy = accuracy_score(labelsTest, classifications) \n",
    "    print(\"accuracy is \", accuracy*100, \"%\")\n",
    "    print(\"              Precision          Recall            F-score\")\n",
    "    #Code taken from https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html\n",
    "    print(\"Macro\", precision_recall_fscore_support(labelsTest, classifications, average='macro'))\n",
    "    print(\"Micro\",precision_recall_fscore_support(labelsTest, classifications, average='micro'))\n",
    "    \n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(labelsTest)): \n",
    "        if classifications[i]==labelsTest[i]==\"ham\":\n",
    "            TP += 1\n",
    "        if labelsTest[i]==\"ham\" and classifications[i]!=labelsTest[i]:\n",
    "            FP += 1\n",
    "        if classifications[i]==labelsTest[i]==\"spam\":\n",
    "            TN += 1\n",
    "        if labelsTest[i]==\"spam\" and classifications[i]!=labelsTest[i]:\n",
    "            FN += 1\n",
    "\n",
    "    print('TP: ',TP)\n",
    "    print('FP: ',FP)\n",
    "    print('TN: ',TN)\n",
    "    print('FN: ',FN)\n",
    "    \n",
    "NaiveBayes(totalTrain,totalTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Logistic Regression Classifier </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticRegression(trainX, testX):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.datasets import load_digits\n",
    "\n",
    "    labelsTrainLR = []\n",
    "    trainTestSet = []\n",
    "    for item in trainX:\n",
    "#         print('item in trainX',item[1])\n",
    "        trainTestSet.append((item[0],item[1]))\n",
    "        labelsTrainLR.append(item[1]) \n",
    "    \n",
    "    for item in testX:\n",
    "        #print(item[1])\n",
    "        trainTestSet.append((item[0],item[1]))\n",
    "        labelsTrainLR.append(item[1]) \n",
    "    \n",
    "    # load the digit dataset \n",
    "    digits = load_digits()\n",
    "#     print(digits)\n",
    "    \n",
    "    # defining feature matrix(X) and response vector(y) \n",
    "    X = digits.data \n",
    "    y = digits.target \n",
    "    \n",
    "    X_train, X_test, y_train, y_test= train_test_split(X,y,test_size=0.4,random_state=0)\n",
    "    \n",
    "    labelsTestLR = []\n",
    "    testSetLR = []\n",
    "    for item in testX:\n",
    "        #print(item[1])\n",
    "        testSetLR.append(item[0])\n",
    "        labelsTestLR.append(item[1]) \n",
    "    \n",
    "#   trainLR = str(trainX)\n",
    "    #print(trainX)\n",
    "    #print(labelsTrainLR)\n",
    "    \n",
    "    LR = LogisticRegression(solver='lbfgs', multi_class='auto')\n",
    "    LR.fit(X_train,y_train)\n",
    "    predictions = LR.predict(X_test)\n",
    "    print(classification_report(y_test,predictions))\n",
    "#    LR = LogisticRegression(random_state=0)\n",
    "#    LRmodel = LR.fit(trainX,trainLR)\n",
    "#    predictions = logisticRegr.predict(testX)\n",
    "        \n",
    "#    classificationsLR = []\n",
    "#    for i,message in enumerate(testSetLR):\n",
    "#         print('message is:', message)\n",
    "#         classification = NBmodel1.predict(message)\n",
    "#        classificationLR = LR.classify(message)\n",
    "#         print('Message ', i, 'is:', classification)\n",
    "#        classificationsLR.append(classificationLR)\n",
    "#         print('classification',classifications[i])\n",
    "#         print('Actual value:', testX[i][1])\n",
    "\n",
    "        \n",
    "#     accuracy = nltk.classify.util.accuracy(NBmodel2, testSet)\n",
    "#     print('accuracy:', accuracy*100,'%')\n",
    "#     prediction = NBmodel1.predict(testSet)\n",
    "    accuracy = accuracy_score(y_test, predictions) \n",
    "    print(\"accuracy is \", accuracy*100, \"%\")\n",
    "    print(\"              Precision          Recall            F-score\")\n",
    "    #Code taken from https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html\n",
    "    print(\"Macro\", precision_recall_fscore_support(y_test, predictions, average='macro'))\n",
    "    print(\"Micro\",precision_recall_fscore_support(y_test, predictions, average='micro'))    \n",
    "    \n",
    "    \n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_test)): \n",
    "        if y_train[i]==y_test[i]==1:\n",
    "            TP += 1\n",
    "        if y_test[i]==1 and y_train[i]!=y_test[i]:\n",
    "            FP += 1\n",
    "        if y_train[i]==y_test[i]==0:\n",
    "            TN += 1\n",
    "        if y_test[i]==0 and y_train[i]!=y_test[i]:\n",
    "            FN += 1\n",
    "\n",
    "    print('TP: ',TP)\n",
    "    print('FP: ',FP)\n",
    "    print('TN: ',TN)\n",
    "    print('FN: ',FN)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        60\n",
      "           1       0.90      0.95      0.92        73\n",
      "           2       1.00      0.94      0.97        71\n",
      "           3       0.96      0.97      0.96        70\n",
      "           4       0.97      1.00      0.98        63\n",
      "           5       0.97      0.94      0.95        89\n",
      "           6       0.97      0.97      0.97        76\n",
      "           7       0.98      0.98      0.98        65\n",
      "           8       0.95      0.90      0.92        78\n",
      "           9       0.92      0.95      0.93        74\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       719\n",
      "   macro avg       0.96      0.96      0.96       719\n",
      "weighted avg       0.96      0.96      0.96       719\n",
      "\n",
      "accuracy is  95.82753824756607 %\n",
      "              Precision          Recall            F-score\n",
      "Macro (0.9597503115630858, 0.9605797685954258, 0.959889505163534, None)\n",
      "Micro (0.9582753824756607, 0.9582753824756607, 0.9582753824756607, None)\n",
      "TP:  12\n",
      "FP:  61\n",
      "TN:  7\n",
      "FN:  53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "LogisticRegression(totalTrainNoDict,totalTestNoDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Evaluation </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the last lines of every classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './trainAnnotated/spam/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f3dce0edb86d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Step 1: get a list of all csv files in target directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmy_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./trainAnnotated/spam/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./trainAnnotated/spam/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mfilelist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mfilesList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './trainAnnotated/spam/'"
     ]
    }
   ],
   "source": [
    "# READING IN THE DATA DIFFERENTLY\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Step 1: get a list of all csv files in target directory\n",
    "my_dir = \"./trainAnnotated/spam/\"\n",
    "files = os.listdir('./trainAnnotated/spam/')\n",
    "filelist = []\n",
    "filesList = []\n",
    "os.chdir( my_dir )\n",
    "\n",
    "# Step 2: Build up list of files:\n",
    "for file in files:\n",
    "    print(file)\n",
    "    fileName, fileExtension = os.path.splitext(file)\n",
    "    filelist.append(fileName) #filename without extension\n",
    "    filesList.append(file) #filename with extension\n",
    "\n",
    "# Step 3: Build up DataFrame:\n",
    "df = pd.DataFrame()\n",
    "for ijk in filelist:\n",
    "    frame = pd.read_csv(ijk)\n",
    "    df = df.append(frame)\n",
    "    \n",
    "print(df)\n",
    "# pathSpam = './trainAnnotated/spam/'\n",
    "# # spamFiles = []\n",
    "# #     # r=root, d=directories, f = files\n",
    "# # \n",
    "# #     for file in f:\n",
    "# #         #if '.txt' in file:\n",
    "# #         df = pd.read_fwf(file)\n",
    "        \n",
    "  #let's load the entities to search\n",
    "# entities = {}\n",
    "\n",
    "# for files in glob.glob(\"*.txt\"):\n",
    "#     fileName, fileExtension = os.path.splitext(files)\n",
    "#     filelist.append(fileName) #filename without extension\n",
    "#     filesList.append(files) #filename with extension\n",
    "\n",
    "print(df)\n",
    "        \n",
    "# for fil in files:   #this load all entities, print to see if they are there\n",
    "#     if (fil[-4:] == '.txt'):\n",
    "#         df = pd.read_fwf(open('./trainAnnotated/spam/'+fil, encoding = 'latin-1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
