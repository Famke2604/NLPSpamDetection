{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"10\"> Spam Detection in emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"3\"> Authors: M. Hooghiemstra and F. Nouwens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Reading in the data </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import random\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------TRAINING DATA----------------------------\n",
    "#Reading in the spam and ham files\n",
    "def readTrain():\n",
    "    pathSpam = './trainAnnotated/spam/'\n",
    "\n",
    "    spamFiles = []\n",
    "    # r=root, d=directories, f = files\n",
    "    for r, d, f in os.walk(pathSpam):\n",
    "        for file in f:\n",
    "            if '.txt' in file:\n",
    "                spamFiles.append(os.path.join(r, file))\n",
    "\n",
    "    spam = [0 for j in range(0,len(spamFiles))]\n",
    "    for index,f in enumerate(spamFiles):\n",
    "        #print(f)\n",
    "        spam[index] = open(f, encoding='latin-1').read().splitlines()\n",
    "\n",
    "    #print(spam)\n",
    "    pathHam = './trainAnnotated/ham/'\n",
    "\n",
    "    hamFiles = []\n",
    "    # r=root, d=directories, f = files\n",
    "    for r, d, f in os.walk(pathHam):\n",
    "        for file in f:\n",
    "            if '.txt' in file:\n",
    "                hamFiles.append(os.path.join(r, file))\n",
    "\n",
    "    ham = [0 for j in range(0,len(hamFiles))]\n",
    "    for index,f in enumerate(hamFiles):\n",
    "        ham[index] = open(f,encoding='latin-1').read().splitlines()\n",
    "    \n",
    "    spamList, hamList = optimalDataFormat(spam, ham)\n",
    "    \n",
    "    return (spamList, hamList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------TEST DATA----------------------------------\n",
    "#Reading in the spam and ham files\n",
    "def readTest():\n",
    "    pathSpam = './testAnnotated/spam/'\n",
    "\n",
    "    spamFiles = []\n",
    "    # r=root, d=directories, f = files\n",
    "    for r, d, f in os.walk(pathSpam):\n",
    "        for file in f:\n",
    "            if '.txt' in file:\n",
    "                spamFiles.append(os.path.join(r, file))\n",
    "\n",
    "    spam = [0 for j in range(0,len(spamFiles))]\n",
    "    for index,f in enumerate(spamFiles):\n",
    "        #print(f)\n",
    "        spam[index] = open(f, encoding='latin-1').read().splitlines()\n",
    "\n",
    "    #print(spam)\n",
    "    pathHam = './testAnnotated/ham/'\n",
    "\n",
    "    hamFiles = []\n",
    "    # r=root, d=directories, f = files\n",
    "    for r, d, f in os.walk(pathHam):\n",
    "        for file in f:\n",
    "            if '.txt' in file:\n",
    "                hamFiles.append(os.path.join(r, file))\n",
    "\n",
    "    ham = [0 for j in range(0,len(hamFiles))]\n",
    "    for index,f in enumerate(hamFiles):\n",
    "        ham[index] = open(f,encoding='latin-1').read().splitlines()\n",
    "    \n",
    "    spamList, hamList = optimalDataFormat(spam, ham)\n",
    "    \n",
    "    return (spamList, hamList)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Pre-processing the data </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDict(text):\n",
    "    dictionary = dict([(word,True) for word in text]) \n",
    "    return dictionary\n",
    "\n",
    "def removeStopWords(text):\n",
    "    from nltk.corpus import stopwords\n",
    "    stop_words = stopwords.words('english') \n",
    "    #print(stop_words)\n",
    "    text = [word for word in text if word not in stop_words]\n",
    "    return text\n",
    "\n",
    "def removePunc(text):\n",
    "    punc = r\"\\\\|\\/|\\%|\\$|\\-|\\^|\\[|\\]|\\<|\\>|\\&|\\(|\\)\"        \n",
    "    text = [word for word in text if not(re.match(punc,word))]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimalDataFormat(spam, ham):\n",
    "    spamList= []\n",
    "    hamList = []\n",
    "\n",
    "    for i,file in enumerate(spam):\n",
    "        tempSent = []\n",
    "        for j,sentence in enumerate(file):\n",
    "            sents = []\n",
    "            #print(spam[i][j])\n",
    "            sentences = sent_tokenize(spam[i][j])\n",
    "    #         print('the sentences:',sentences)\n",
    "            for sent in sentences:\n",
    "    #             print('sentence:',sent)\n",
    "                words = word_tokenize(sent)\n",
    "    #             print('words tokenized:',words)\n",
    "                words = removeStopWords(words)\n",
    "                words = removePunc(words)\n",
    "                sents += words\n",
    "    #             print('preprocessed words:',sents)\n",
    "    #             print(\"end of for loop sent in sentences\")\n",
    "            tempSent += sents\n",
    "    #         print('sentences in file',tempSent)\n",
    "        spamList.append(tempSent)\n",
    "    #     print('spamlist:',spamList)\n",
    "\n",
    "    for i,file in enumerate(ham):\n",
    "        tempSent = []\n",
    "        for j,sentence in enumerate(file):\n",
    "            sents = []\n",
    "            #print(ham[i][j])\n",
    "            sentences = sent_tokenize(ham[i][j])\n",
    "    #         print('the sentences:',sentences)\n",
    "            for sent in sentences:\n",
    "    #             print('sentence:',sent)\n",
    "                words = word_tokenize(sent)\n",
    "    #             print('words tokenized:',words)\n",
    "                words = removeStopWords(words)\n",
    "                words = removePunc(words)\n",
    "                sents += words\n",
    "    #             print('preprocessed words:',sents)\n",
    "    #             print(\"end of for loop sent in sentences\")\n",
    "            tempSent += sents\n",
    "    #         print('sentences in file',tempSent)\n",
    "        hamList.append(tempSent)\n",
    "    #     print('hamlist:',hamList)\n",
    "    return (spamList, hamList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTotalSet(spamList, hamList):\n",
    "    hamList2 = []\n",
    "    spamList2 = []\n",
    "    for mail in hamList:\n",
    "        hamList2.append((createDict(mail),\"ham\"))\n",
    "\n",
    "    for mail in spamList:\n",
    "        spamList2.append((createDict(mail),\"spam\"))\n",
    "\n",
    "\n",
    "    #We combine the two dataset lists to eventually train the classifiers\n",
    "    totalTrain = hamList2 + spamList2\n",
    "\n",
    "    #To get unbiased results, we shuffle the dataset\n",
    "    random.shuffle(totalTrain)\n",
    "    return totalTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTotalSetNoDict(spamList, hamList):\n",
    "    hamList2 = []\n",
    "    spamList2 = []\n",
    "    for i,message in enumerate(hamList):\n",
    "        hamList2.append((hamList[i],0))\n",
    "\n",
    "    for i,message in enumerate(spamList):\n",
    "        hamList2.append((spamList[i],1))\n",
    "        \n",
    "\n",
    "    #print('hamList', hamList2[1])\n",
    "    #We combine the two dataset lists to eventually train the classifiers\n",
    "    totalTrain = hamList2 + spamList2\n",
    "\n",
    "    #To get unbiased results, we shuffle the dataset\n",
    "    random.shuffle(totalTrain)\n",
    "    return totalTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running the whole code to obtain the total train data:\n",
    "spamList, hamList = readTrain()\n",
    "totalTrain = createTotalSet(spamList,hamList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "spamList, hamList = readTest()\n",
    "totalTest = createTotalSet(spamList, hamList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create train set\n",
      "create test set\n"
     ]
    }
   ],
   "source": [
    "print('create train set')\n",
    "spamList, hamList = readTrain()\n",
    "totalTrainNoDict = createTotalSetNoDict(spamList,hamList)\n",
    "print('create test set')\n",
    "spamList, hamList = readTest()\n",
    "totalTestNoDict = createTotalSetNoDict(spamList, hamList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Na√Øve Bayes Classifier </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is  97.46666666666667 %\n",
      "              Precision          Recall            F-score\n",
      "Macro (0.9756441682818379, 0.9746666666666666, 0.9746536442723461, None)\n",
      "Micro (0.9746666666666667, 0.9746666666666667, 0.9746666666666667, None)\n"
     ]
    }
   ],
   "source": [
    "#NAIVE BAYES CLASSIFIER\n",
    "def NaiveBayes(trainX,testX):\n",
    "    from sklearn.naive_bayes import MultinomialNB  \n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from nltk.classify import NaiveBayesClassifier\n",
    "    \n",
    "    labelsTest = []\n",
    "    testSet = []\n",
    "    for item in testX:\n",
    "       # print(item[1])\n",
    "        testSet.append(item[0])\n",
    "        labelsTest.append(item[1]) \n",
    "        \n",
    "    labelsTrain = []\n",
    "    trainSet = []\n",
    "    for item in trainX:\n",
    "       # print(item[1])\n",
    "        trainSet.append((item[0],item[1]))\n",
    "        labelsTrain.append(item[1]) \n",
    "    \n",
    "#     print(trainSet[0])\n",
    "\n",
    "    NBmodel1 = MultinomialNB()\n",
    "#     for i, message in enumerate(trainSet):\n",
    "#         NBmodel1.fit(trainSet[i],labelsTrain)\n",
    "    \n",
    "    #NBmodel1.fit(trainSet,labelsTrain)\n",
    "#     print('trainX',trainX[1])\n",
    "    NBmodel2 = NaiveBayesClassifier.train(trainX)\n",
    "    \n",
    "\n",
    "    classifications = []\n",
    "    for i,message in enumerate(testSet):\n",
    "#         print('message is:', message)\n",
    "#         classification = NBmodel1.predict(message)\n",
    "        classification = NBmodel2.classify(message)\n",
    "#         print('Message ', i, 'is:', classification)\n",
    "        classifications.append(classification)\n",
    "#         print('classification',classifications[i])\n",
    "#         print('Actual value:', testX[i][1])\n",
    "\n",
    "        \n",
    "#     accuracy = nltk.classify.util.accuracy(NBmodel2, testSet)\n",
    "#     print('accuracy:', accuracy*100,'%')\n",
    "#     prediction = NBmodel1.predict(testSet)\n",
    "    accuracy = accuracy_score(labelsTest, classifications) \n",
    "    print(\"accuracy is \", accuracy*100, \"%\")\n",
    "    print(\"              Precision          Recall            F-score\")\n",
    "    #Code taken from https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html\n",
    "    print(\"Macro\", precision_recall_fscore_support(labelsTest, classifications, average='macro'))\n",
    "    print(\"Micro\",precision_recall_fscore_support(labelsTest, classifications, average='micro'))\n",
    "    \n",
    "NaiveBayes(totalTrain,totalTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Logistic Regression Classifier </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Subject', ':', 'new', 'hire', 'dinner', 'rsvps', \"'\", 'forget', 'let', 'know', 'interested', 'attending', 'new', 'hire', 'dinner', '6', 'pm', 'thursday', ',', 'april', '26', 'th', '!', 'held', 'oritalia', 'westin', 'hotel', '.', 'please', 'indicate', 'meal', 'selection', 'meat', 'beef', ',', 'veggie', 'pasta', '.', 'need', 'submit', 'final', 'entree', 'numbers', 'thursday', 'morning', '.', 'thanks', ',', 'grace', 'x', '8321']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-88dfce9857ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# print(totalTrainNoDict[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotalTrainNoDict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotalTestNoDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-88dfce9857ee>\u001b[0m in \u001b[0;36mLogisticRegression\u001b[0;34m(trainX, testX)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mLR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mLRmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainSetLR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabelsTrainLR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[0;32m-> 1288\u001b[0;31m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[1;32m   1289\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    757\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "def LogisticRegression(trainX, testX):\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    labelsTrainLR = []\n",
    "    trainSetLR = []\n",
    "    for item in trainX:\n",
    "       # print(item[1])\n",
    "        trainSetLR.append((item[0]))\n",
    "        labelsTrainLR.append(item[1]) \n",
    "    \n",
    "    print(trainSetLR[0])\n",
    "    labelsTestLR = []\n",
    "    testSetLR = []\n",
    "    for item in testX:\n",
    "       # print(item[1])\n",
    "        testSetLR.append(item[0])\n",
    "        labelsTestLR.append(item[1]) \n",
    "    \n",
    "    LR = LogisticRegression(solver='liblinear', penalty='l1',class_weight='balanced')\n",
    "    LRmodel = LR.fit(trainSetLR,labelsTrainLR)\n",
    "    predictions = LR.predict(testX)\n",
    "        \n",
    "    classificationsLR = []\n",
    "    for i,message in enumerate(testSetLR):\n",
    "#         print('message is:', message)\n",
    "#         classification = NBmodel1.predict(message)\n",
    "        classificationLR = LR.classify(message)\n",
    "#         print('Message ', i, 'is:', classification)\n",
    "        classificationsLR.append(classificationLR)\n",
    "#         print('classification',classifications[i])\n",
    "#         print('Actual value:', testX[i][1])\n",
    "\n",
    "        \n",
    "#     accuracy = nltk.classify.util.accuracy(NBmodel2, testSet)\n",
    "#     print('accuracy:', accuracy*100,'%')\n",
    "#     prediction = NBmodel1.predict(testSet)\n",
    "    accuracy = accuracy_score(labelsTestLR, classificationsLR) \n",
    "    print(\"accuracy is \", accuracy*100, \"%\")\n",
    "    print(\"              Precision          Recall            F-score\")\n",
    "    #Code taken from https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html\n",
    "    print(\"Macro\", precision_recall_fscore_support(labelsTest, classifications, average='macro'))\n",
    "    print(\"Micro\",precision_recall_fscore_support(labelsTest, classifications, average='micro'))\n",
    "    \n",
    "\n",
    "# print(totalTrainNoDict[1])\n",
    "LogisticRegression(totalTrainNoDict,totalTestNoDict)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Custom Word Filtering Classifier </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Evaluation </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
